import streamlit as st
import google.generativeai as genai
import json
import logging

# --- Configuration ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# It's recommended to use st.secrets for your API key in deployment.
try:
    # Replace with your key or use Streamlit secrets
    genai.configure(api_key="") 
except Exception as e:
    st.error(f"Failed to configure Google AI: {e}")
    st.info("Please make sure you have set your API key.")
    st.stop()

# --- AI Model Setup ---
@st.cache_resource
def get_model():
    """Initializes and caches the generative AI model."""
    try:
        return genai.GenerativeModel('gemini-1.5-flash-latest')
    except Exception as e:
        st.error(f"Failed to initialize the AI model. Error: {e}")
        st.stop()

model = get_model()

# --- NEW: ChatManager Class for AI and Memory Logic ---
class ChatManager:
    """Manages all AI interaction, including the hybrid memory system."""
    def __init__(self, model, memory_token_limit=4000, recent_message_count=8):
        self.model = model
        self.memory_token_limit = memory_token_limit
        self.recent_message_count = recent_message_count

    def count_tokens(self, history):
        """Counts the total tokens in the chat history for precise memory triggers."""
        full_text = " ".join([msg['text'] for msg in history])
        try:
            return self.model.count_tokens(full_text).total_tokens
        except Exception as e:
            logging.error(f"Could not count tokens: {e}")
            return len(full_text) // 4 # Fallback estimate

    def summarize_conversation(self, history):
        """Asks the model to summarize older parts of the game history."""
        logging.info("Summarizing older game history for long-term memory...")
        history_text = "\n".join([f"{msg['role'].title()}: {msg['text']}" for msg in history])
        
        prompt = f"""You are the Chronicler, a master historian. Read the following game transcript and summarize the key events, plot developments, major player decisions, and important NPCs into a single, dense paragraph. This summary will serve as the long-term memory for the game's Dungeon Master.

        TRANSCRIPT TO SUMMARIZE:
        {history_text}

        CONCISE SUMMARY:"""
        try:
            response = self.model.generate_content(prompt)
            return response.text.strip()
        except Exception as e:
            logging.error(f"Error during summarization: {e}")
            return "The Chronicler's memory fades..."

    def get_dm_response(self, user_input: str):
        """
        Generates the Dungeon Master's response, manages memory,
        and updates the game state.
        """
        # Add user's action to the main history first
        st.session_state.chat_history.append({"role": "user", "text": user_input})
        
        history = st.session_state.chat_history
        long_term_memory = "The story is just beginning."
        short_term_history = history # By default, use the full history

        # Check if token count exceeds the limit to activate hybrid memory
        total_tokens = self.count_tokens(history)
        logging.info(f"Current conversation token count: {total_tokens}")

        if total_tokens > self.memory_token_limit:
            logging.info("Token limit exceeded. Activating hybrid memory.")
            
            # Split history into old and recent parts
            history_to_summarize = history[:-self.recent_message_count]
            short_term_history = history[-self.recent_message_count:]

            # Create the long-term memory summary
            long_term_memory = self.summarize_conversation(history_to_summarize)
            st.toast("Long-term memory updated!", icon="üìú")

        # Construct the detailed prompt for the AI Dungeon Master
        system_prompt = f"""
        You are an AI Dungeon Master. Your response MUST be a single, valid JSON object.

        ---
        **THE STORY SO FAR (Long-Term Memory):**
        {long_term_memory}
        ---
        **CURRENT PLAYER INVENTORY (Immediate State):**
        {json.dumps(st.session_state.inventory, indent=2)}
        ---
        **RECENT EVENTS (Short-Term Memory):**
        {json.dumps(short_term_history, indent=2)}
        ---
        **PLAYER'S CURRENT ACTION:**
        {user_input}
        ---

        Based on all context, generate a response as a single JSON object with "narrative_response" (string) and "item_changes" (list of objects with "action", "name", "description").
        """

        try:
            response = self.model.generate_content(system_prompt)
            ai_response_text = response.text.strip().replace("```json", "").replace("```", "")
            
            ai_response = json.loads(ai_response_text)
            narrative = ai_response.get("narrative_response", "The DM seems confused. Please try again.")
            item_changes = ai_response.get("item_changes", [])

            # Update inventory based on AI's instructions
            for change in item_changes:
                if all(k in change for k in ["action", "name", "description"]):
                    action, item_name, item_desc = change["action"], change["name"], change["description"]
                    if action == "add":
                        st.session_state.inventory[item_name] = {"description": item_desc}
                        st.toast(f"You acquired: {item_name}!", icon="üì¶")
                    elif action == "remove" and item_name in st.session_state.inventory:
                        del st.session_state.inventory[item_name]
                        st.toast(f"You used: {item_name}.", icon="üóëÔ∏è")
            
            # Add the narrative part of the response to history
            st.session_state.chat_history.append({"role": "assistant", "text": narrative})
            
        except json.JSONDecodeError:
            error_message = f"The DM's response was not valid JSON. Response received:\n\n{ai_response_text}"
            st.session_state.chat_history.append({"role": "assistant", "text": error_message})
        except Exception as e:
            error_message = f"An unexpected error occurred: {e}."
            st.session_state.chat_history.append({"role": "assistant", "text": error_message})

# --- Game State Management ---
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
if 'inventory' not in st.session_state:
    st.session_state.inventory = {}
if 'game_started' not in st.session_state:
    st.session_state.game_started = False

# --- Main App Interface ---
st.set_page_config(page_title="The Generative Bard", page_icon="üßô", layout="wide")
st.title("üßô The Generative Bard: Hybrid Memory Edition")

# --- Sidebar Controls ---
with st.sidebar:
    st.header("‚öôÔ∏è Memory Configuration")
    memory_token_limit = st.slider(
        "Memory Trigger (Tokens)",
        min_value=1000, max_value=8000, value=4000, step=500,
        help="Total tokens before summarization is triggered."
    )
    recent_message_count = st.slider(
        "Recent Events to Keep",
        min_value=2, max_value=12, value=8, step=2,
        help="Number of recent messages to keep verbatim for short-term context."
    )
    
    st.header("üéí Inventory")
    if st.session_state.inventory:
        for item, details in st.session_state.inventory.items():
            st.markdown(f"**{item}**")
            st.markdown(f"<small>{details['description']}</small>", unsafe_allow_html=True)
            st.divider()
    else:
        st.info("Your inventory is empty.")

# --- Initialize or Re-initialize ChatManager if settings change ---
if ('chat_manager' not in st.session_state or 
    st.session_state.get('token_limit') != memory_token_limit or 
    st.session_state.get('recent_count') != recent_message_count):
    st.session_state.chat_manager = ChatManager(
        model, 
        memory_token_limit=memory_token_limit, 
        recent_message_count=recent_message_count
    )
    st.session_state.token_limit = memory_token_limit
    st.session_state.recent_count = recent_message_count

# --- Game Flow ---
if not st.session_state.game_started:
    if st.button("Start New Adventure", type="primary"):
        st.session_state.game_started = True
        with st.spinner("The Bard prepares the opening scene..."):
            initial_prompt = "The player is starting a new game. Describe the first scene and provide them with one or two initial items. Keep the narrative to a few sentences."
            st.session_state.chat_manager.get_dm_response(initial_prompt)
        st.rerun()
else:
    # Display chat history
    chat_container = st.container(height=500, border=True)
    with chat_container:
        for message in st.session_state.chat_history:
            role = "user" if message["role"] == "user" else "assistant"
            with st.chat_message(role):
                st.markdown(message["text"])
    
    # Handle user input
    if user_prompt := st.chat_input("What do you do?"):
        with st.spinner("The DM considers your action..."):
            st.session_state.chat_manager.get_dm_response(user_prompt)
        st.rerun()
